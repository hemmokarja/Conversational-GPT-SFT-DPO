{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d51705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemmo.karja/Desktop/Omat/projects/GPT2-Fine-Tune/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from model import GPT\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74340fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model:Initializing a pre-trained gpt2 model...\n",
      "INFO:model:Initialized GPT with 124.44 M parameters (of which 38.60 M in embeddings)\n",
      "INFO:model:Loading pre-trained weights from HuggingFace...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm()\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT.from_pretrained(\"gpt2\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9d8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9ad819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a land far, far away, there lived a man who, while at great leisure, used to write to the people of the province of Merelum, calling for the assistance of the nation. The man took his name and put it to the test of the citizens of the province, and\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Once upon a time in a land far, far away, there lived a\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "output_ids = model.generate(input_ids, max_tokens=50, temperature=1.0, top_k=40)\n",
    "generated_text = tokenizer.decode(output_ids[0])\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de208070",
   "metadata": {},
   "source": [
    "### Add new tokens to tokenizer and model\n",
    "\n",
    "**im tokens usage**\n",
    "\n",
    "```bash\n",
    "<|im_start|>user\n",
    "How do I bake a cake?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Here's how to bake a basic cake...<|im_end|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4359887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model:Extended token embeddings: 50257 -> 50260\n",
      "INFO:model:Set padding embedding at index 50259 to zero\n"
     ]
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\n",
    "    \"additional_special_tokens\": [\"<|im_start|>\", \"<|im_end|>\"],\n",
    "    \"pad_token\": \"<|pad|>\",\n",
    "})\n",
    "\n",
    "tokenizer.im_start_token = \"<|im_start|>\"\n",
    "tokenizer.im_end_token = \"<|im_end|>\"\n",
    "\n",
    "tokenizer.im_start_token_id = tokenizer.convert_tokens_to_ids(\"<|im_start|>\")\n",
    "tokenizer.im_end_token_id = tokenizer.convert_tokens_to_ids(\"<|im_end|>\")\n",
    "\n",
    "model.extend_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.set_padding_embedding(tokenizer.pad_token_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2-fine-tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
