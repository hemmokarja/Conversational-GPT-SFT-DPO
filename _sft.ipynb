{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f97b05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemmo.karja/Desktop/Omat/projects/GPT2-Fine-Tune/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from src import oasst, text_util\n",
    "from src.model import GPT2\n",
    "from src.trainer import Trainer, TrainerConfig\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af2d0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES_TRAIN = 2000\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=8,\n",
    "    gradient_acc_steps=1,\n",
    "    log_interval=8,\n",
    "    compile=False,\n",
    "    base_learning_rate=1e-4,\n",
    "    min_learning_rate=1e-6,\n",
    "    lr_step_size=100,\n",
    "    lr_gamma=0.75,\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.95),\n",
    "    grad_clip=1.0,\n",
    "    num_workers=0,\n",
    "    prefetch_factor=None,\n",
    "    pin_memory=False,\n",
    "    validation_samples=100,\n",
    "    validation_interval=200,\n",
    "    generate_sample_prompts=[\n",
    "        \"How do I bake a cake?\",\n",
    "        \"What are the best attractions in Rome, Italy?\",\n",
    "        \"What does an architect do?\"\n",
    "    ],\n",
    "    generate_max_tokens=200,\n",
    "    generate_temperature=1.0,\n",
    "    generate_top_k=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a360db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "text_util.add_pad_token_to_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb297a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted and parsed 20147 conversations\n",
      "Extracted and parsed 1002 conversations\n"
     ]
    }
   ],
   "source": [
    "train_dataset, validation_dataset = oasst.load_oasst_dataset(\"oasst1\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbdf76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model:Initializing a pre-trained gpt2 model...\n",
      "INFO:src.model:Overriding dropout to 0.1\n",
      "INFO:src.model:Initialized GPT with 124.44 M parameters (of which 38.60 M in embeddings)\n",
      "INFO:src.model:Loading pre-trained weights from HuggingFace...\n"
     ]
    }
   ],
   "source": [
    "model = GPT2.from_pretrained(\"gpt2\", override_args={\"dropout\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da4b3b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model:Initialized GPT with 124.44 M parameters (of which 38.60 M in embeddings)\n"
     ]
    }
   ],
   "source": [
    "fine_tuneable = model.to_fine_tuneable()\n",
    "fine_tuneable.add_padding_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0610b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer =  Trainer(\n",
    "    trainer_config, fine_tuneable, tokenizer, train_dataset, validation_dataset, DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f04425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.trainer:Staring model training for 2000 samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ iter:      0 â”‚ ðŸ“Š samples:        8 â”‚ ðŸ“‰ loss: 94.1180 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:      1 â”‚ ðŸ“Š samples:       16 â”‚ ðŸ“‰ loss: 67.4277 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:      2 â”‚ ðŸ“Š samples:       24 â”‚ ðŸ“‰ loss: 49.0198 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:      3 â”‚ ðŸ“Š samples:       32 â”‚ ðŸ“‰ loss: 38.2399 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:      4 â”‚ ðŸ“Š samples:       40 â”‚ ðŸ“‰ loss: 31.7503 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:      5 â”‚ ðŸ“Š samples:       48 â”‚ ðŸ“‰ loss: 27.3478 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:      6 â”‚ ðŸ“Š samples:       56 â”‚ ðŸ“‰ loss: 24.0879 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:      7 â”‚ ðŸ“Š samples:       64 â”‚ ðŸ“‰ loss: 21.5943 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:      8 â”‚ ðŸ“Š samples:       72 â”‚ ðŸ“‰ loss: 10.3398 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:      9 â”‚ ðŸ“Š samples:       80 â”‚ ðŸ“‰ loss:  5.6349 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     10 â”‚ ðŸ“Š samples:       88 â”‚ ðŸ“‰ loss:  4.5529 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     11 â”‚ ðŸ“Š samples:       96 â”‚ ðŸ“‰ loss:  4.2332 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     12 â”‚ ðŸ“Š samples:      104 â”‚ ðŸ“‰ loss:  3.9641 â”‚ ðŸ“ˆ lr:  1.00e-04 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     13 â”‚ ðŸ“Š samples:      112 â”‚ ðŸ“‰ loss:  3.6780 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     14 â”‚ ðŸ“Š samples:      120 â”‚ ðŸ“‰ loss:  3.4647 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     15 â”‚ ðŸ“Š samples:      128 â”‚ ðŸ“‰ loss:  3.3509 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     16 â”‚ ðŸ“Š samples:      136 â”‚ ðŸ“‰ loss:  3.2002 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     17 â”‚ ðŸ“Š samples:      144 â”‚ ðŸ“‰ loss:  3.1241 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     18 â”‚ ðŸ“Š samples:      152 â”‚ ðŸ“‰ loss:  3.0167 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     19 â”‚ ðŸ“Š samples:      160 â”‚ ðŸ“‰ loss:  2.9931 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     20 â”‚ ðŸ“Š samples:      168 â”‚ ðŸ“‰ loss:  2.9250 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     21 â”‚ ðŸ“Š samples:      176 â”‚ ðŸ“‰ loss:  2.8772 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     22 â”‚ ðŸ“Š samples:      184 â”‚ ðŸ“‰ loss:  2.9053 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     23 â”‚ ðŸ“Š samples:      192 â”‚ ðŸ“‰ loss:  2.8672 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     24 â”‚ ðŸ“Š samples:      200 â”‚ ðŸ“‰ loss:  2.8635 â”‚ ðŸ“ˆ lr:  7.50e-05 â”‚ âš¡    1 samples/s\n",
      "\n",
      "================================================================================\n",
      "VALIDATION RESULTS\n",
      "================================================================================\n",
      "ðŸ“Š METRICS (samples seen: 200)\n",
      "----------------------------------------\n",
      "  Loss:       2.8909\n",
      "  Accuracy:   46.2%\n",
      "  Perplexity: 21.37\n",
      "\n",
      "ðŸ¤– SAMPLE COMPLETIONS\n",
      "----------------------------------------\n",
      "\n",
      "[Sample 1]\n",
      "Prompt: How do I bake a cake?\n",
      "Response: In this scenario you ask your cake bakeries to bake a cake that is ready to go into the oven and then bake it.You can bake the cake up with butter, flour and sugar. You can bake it in a small pan with butter, buttermilk and baking powder. If you use a baking powder, it will only get better with time. You can give it a quick stir, buttermilk and baking powder are important\n",
      "------------------------------\n",
      "\n",
      "[Sample 2]\n",
      "Prompt: What are the best attractions in Rome, Italy?\n",
      "Response: To help you find out what is best in Rome, your first thing to do is to visit your local tourist site to check out the attractions. They are usually located on the beautiful side of town\n",
      "you can enjoy a great Italian cuisine and drinks\n",
      "------------------------------\n",
      "\n",
      "[Sample 3]\n",
      "Prompt: What does an architect do?\n",
      "Response: I prefer to do architects only in terms of the basics of Architects. As I say, your skills have an important impact in building efficient buildings. As architects you should get skilled, but not necessarily experienced, in the construction.  You should find success in building efficient buildings like the ones in the above videos, without needing an expert architect and without a budget!STANDARD\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ”„ iter:     25 â”‚ ðŸ“Š samples:      208 â”‚ ðŸ“‰ loss:  2.9545 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     26 â”‚ ðŸ“Š samples:      216 â”‚ ðŸ“‰ loss:  2.9508 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     27 â”‚ ðŸ“Š samples:      224 â”‚ ðŸ“‰ loss:  2.9127 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     28 â”‚ ðŸ“Š samples:      232 â”‚ ðŸ“‰ loss:  2.8665 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     29 â”‚ ðŸ“Š samples:      240 â”‚ ðŸ“‰ loss:  2.8502 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     30 â”‚ ðŸ“Š samples:      248 â”‚ ðŸ“‰ loss:  2.7831 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     31 â”‚ ðŸ“Š samples:      256 â”‚ ðŸ“‰ loss:  2.7108 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     32 â”‚ ðŸ“Š samples:      264 â”‚ ðŸ“‰ loss:  2.7060 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    1 samples/s\n",
      "ðŸ”„ iter:     33 â”‚ ðŸ“Š samples:      272 â”‚ ðŸ“‰ loss:  2.6601 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     34 â”‚ ðŸ“Š samples:      280 â”‚ ðŸ“‰ loss:  2.7261 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    0 samples/s\n",
      "ðŸ”„ iter:     35 â”‚ ðŸ“Š samples:      288 â”‚ ðŸ“‰ loss:  2.7447 â”‚ ðŸ“ˆ lr:  5.63e-05 â”‚ âš¡    0 samples/s\n"
     ]
    }
   ],
   "source": [
    "trainer.train(N_SAMPLES_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4d593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2-fine-tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
